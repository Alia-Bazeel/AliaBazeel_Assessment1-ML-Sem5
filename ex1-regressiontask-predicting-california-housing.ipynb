{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7876,"sourceType":"datasetVersion","datasetId":5227}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Regression Task: *Predicting California Housing Prices***","metadata":{}},{"cell_type":"markdown","source":"#### Predicting California Housing Prices Using Linear Regression. ***California Housing Prices dataset***","metadata":{}},{"cell_type":"markdown","source":"## **Step 1: Import Libraries**\n#### *The basic libraries that are required for data analysis and machine learning.*","metadata":{}},{"cell_type":"code","source":"import pandas as pd              # for handling data\nimport numpy as np               # for numerical operations\nimport matplotlib.pyplot as plt  # for data visualization\nimport seaborn as sns\nimport sklearn                   # scikit-learn library (machine learning tools)\nfrom sklearn.model_selection import train_test_split # split dataset into training and testing sets\nfrom sklearn.linear_model import LinearRegression    # machine learning algorithm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # evaluating model performance","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:36.753578Z","iopub.execute_input":"2025-11-03T07:35:36.754481Z","iopub.status.idle":"2025-11-03T07:35:39.171230Z","shell.execute_reply.started":"2025-11-03T07:35:36.754438Z","shell.execute_reply":"2025-11-03T07:35:39.170285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 2: Load and Check Data**\n#### *Load the dataset and look at the first few rows to understand the structure.*","metadata":{}},{"cell_type":"code","source":"price = pd.read_csv(\"/kaggle/input/california-housing-prices/housing.csv\")\n\n#print(price)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.172972Z","iopub.execute_input":"2025-11-03T07:35:39.173474Z","iopub.status.idle":"2025-11-03T07:35:39.253347Z","shell.execute_reply.started":"2025-11-03T07:35:39.173441Z","shell.execute_reply":"2025-11-03T07:35:39.252412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.info() #complete information  of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.254358Z","iopub.execute_input":"2025-11-03T07:35:39.254607Z","iopub.status.idle":"2025-11-03T07:35:39.283159Z","shell.execute_reply.started":"2025-11-03T07:35:39.254588Z","shell.execute_reply":"2025-11-03T07:35:39.282212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.head() #first 5 rows of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.285206Z","iopub.execute_input":"2025-11-03T07:35:39.285450Z","iopub.status.idle":"2025-11-03T07:35:39.312089Z","shell.execute_reply.started":"2025-11-03T07:35:39.285430Z","shell.execute_reply":"2025-11-03T07:35:39.311132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.tail() #last 5 rows of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.313000Z","iopub.execute_input":"2025-11-03T07:35:39.313298Z","iopub.status.idle":"2025-11-03T07:35:39.327879Z","shell.execute_reply.started":"2025-11-03T07:35:39.313271Z","shell.execute_reply":"2025-11-03T07:35:39.326956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.shape #number of rows & coloumns of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.328640Z","iopub.execute_input":"2025-11-03T07:35:39.328948Z","iopub.status.idle":"2025-11-03T07:35:39.341794Z","shell.execute_reply.started":"2025-11-03T07:35:39.328917Z","shell.execute_reply":"2025-11-03T07:35:39.340845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.describe() #statistical summary of numerical columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.342691Z","iopub.execute_input":"2025-11-03T07:35:39.343103Z","iopub.status.idle":"2025-11-03T07:35:39.395487Z","shell.execute_reply.started":"2025-11-03T07:35:39.343079Z","shell.execute_reply":"2025-11-03T07:35:39.394455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 3: Preprocessing Data**\n#### *-Handle missing values*\n#### *-Encode categorical column (ocean_proximity)*\n#### *-Split features/target*","metadata":{}},{"cell_type":"code","source":"price.dropna(inplace=True)    # Drop rows with missing values\n\n# Encode categorical feature using One-Hot Encoding\nprice = pd.get_dummies(price, drop_first=True)\n\n# Define features X and target y\nX = price.drop(\"median_house_value\", axis=1)\ny = price[\"median_house_value\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.396483Z","iopub.execute_input":"2025-11-03T07:35:39.396838Z","iopub.status.idle":"2025-11-03T07:35:39.417552Z","shell.execute_reply.started":"2025-11-03T07:35:39.396807Z","shell.execute_reply":"2025-11-03T07:35:39.416593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.418637Z","iopub.execute_input":"2025-11-03T07:35:39.419041Z","iopub.status.idle":"2025-11-03T07:35:39.424295Z","shell.execute_reply.started":"2025-11-03T07:35:39.419018Z","shell.execute_reply":"2025-11-03T07:35:39.423462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.428362Z","iopub.execute_input":"2025-11-03T07:35:39.428916Z","iopub.status.idle":"2025-11-03T07:35:39.438401Z","shell.execute_reply.started":"2025-11-03T07:35:39.428885Z","shell.execute_reply":"2025-11-03T07:35:39.437355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 4: Split the data into Training and Testing Sets**\n#### *We separate the features (X) and the target (y).*\n#### *Split into 80% training and 20% testing data*","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.439346Z","iopub.execute_input":"2025-11-03T07:35:39.440015Z","iopub.status.idle":"2025-11-03T07:35:39.457726Z","shell.execute_reply.started":"2025-11-03T07:35:39.439986Z","shell.execute_reply":"2025-11-03T07:35:39.456604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.458769Z","iopub.execute_input":"2025-11-03T07:35:39.459062Z","iopub.status.idle":"2025-11-03T07:35:39.464800Z","shell.execute_reply.started":"2025-11-03T07:35:39.459035Z","shell.execute_reply":"2025-11-03T07:35:39.463847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 5: Feature Scaling**","metadata":{}},{"cell_type":"code","source":"# Scaling numerical input data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.465740Z","iopub.execute_input":"2025-11-03T07:35:39.466088Z","iopub.status.idle":"2025-11-03T07:35:39.525437Z","shell.execute_reply.started":"2025-11-03T07:35:39.466063Z","shell.execute_reply":"2025-11-03T07:35:39.524482Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 6: Train - Model 1: Linear Regression**\n#### *We create the model and fit it (train it) on the training data.*","metadata":{}},{"cell_type":"code","source":"model_lin = LinearRegression()         # Initialize Linear Regression Model\nmodel_lin.fit(X_train_scaled, y_train) # Fit model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.526416Z","iopub.execute_input":"2025-11-03T07:35:39.526656Z","iopub.status.idle":"2025-11-03T07:35:39.587233Z","shell.execute_reply.started":"2025-11-03T07:35:39.526637Z","shell.execute_reply":"2025-11-03T07:35:39.586522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 7: Make Predictions - Model 1: Linear Regression**\n#### *Use the trained model to predict on the test set.*","metadata":{}},{"cell_type":"code","source":"y_pred_lin = model_lin.predict(X_test_scaled) # Predict test values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.587861Z","iopub.execute_input":"2025-11-03T07:35:39.588103Z","iopub.status.idle":"2025-11-03T07:35:39.599423Z","shell.execute_reply.started":"2025-11-03T07:35:39.588082Z","shell.execute_reply":"2025-11-03T07:35:39.598724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_pred_lin","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.599971Z","iopub.execute_input":"2025-11-03T07:35:39.600179Z","iopub.status.idle":"2025-11-03T07:35:39.629012Z","shell.execute_reply.started":"2025-11-03T07:35:39.600160Z","shell.execute_reply":"2025-11-03T07:35:39.627156Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 8: Evaluate Model - Model 1: Linear Regression**","metadata":{}},{"cell_type":"code","source":"# Evaluation metrics\nmae_lin = mean_absolute_error(y_test, y_pred_lin)\nmse_lin = mean_squared_error(y_test, y_pred_lin)\nrmse_lin = np.sqrt(mse_lin)\nr2_lin = r2_score(y_test, y_pred_lin)\n\nprint(\"Linear Model Performance:\")\nprint(\"Mean Absolute Error:\", round(mae_lin, 2))\nprint(\"Mean Squared Error:\", round(mse_lin, 2))\nprint(\"RMSE:\", round(rmse_lin, 2))\nprint(\"R² Score:\", round(r2_lin, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.630039Z","iopub.execute_input":"2025-11-03T07:35:39.630330Z","iopub.status.idle":"2025-11-03T07:35:39.649304Z","shell.execute_reply.started":"2025-11-03T07:35:39.630304Z","shell.execute_reply":"2025-11-03T07:35:39.648134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 9: Visualize - Model 1: *Linear Regression***","metadata":{}},{"cell_type":"markdown","source":"## -------- 9.1. *Actual vs Predicted Plot*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nsns.scatterplot(x=y_test, y=y_pred_lin)\nplt.xlabel(\"Actual House Value\")\nplt.ylabel(\"Predicted House Value\")\nplt.title(\"Linear Regression: Actual vs Predicted House Prices\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.651287Z","iopub.execute_input":"2025-11-03T07:35:39.652261Z","iopub.status.idle":"2025-11-03T07:35:39.984390Z","shell.execute_reply.started":"2025-11-03T07:35:39.652231Z","shell.execute_reply":"2025-11-03T07:35:39.983316Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 9.2. *Error Distribution*","metadata":{}},{"cell_type":"code","source":"errors_lin = y_test - y_pred_lin\nplt.figure(figsize=(7,6))\nsns.histplot(errors_lin, bins=50)\nplt.xlabel(\"Prediction Error\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Linear Regression: Error Distribution\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.985439Z","iopub.execute_input":"2025-11-03T07:35:39.985781Z","iopub.status.idle":"2025-11-03T07:35:40.257240Z","shell.execute_reply.started":"2025-11-03T07:35:39.985754Z","shell.execute_reply":"2025-11-03T07:35:40.256221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 9.3. *Regression Line Chart*\n#### *Helps show linear relationship*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nplt.plot(y_test.values[:100], label=\"Actual\")\nplt.plot(y_pred_lin[:100], label=\"Predicted\")\nplt.title(\"Linear Regression: Actual vs Predicted (sample 100)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:40.258180Z","iopub.execute_input":"2025-11-03T07:35:40.258478Z","iopub.status.idle":"2025-11-03T07:35:40.467468Z","shell.execute_reply.started":"2025-11-03T07:35:40.258454Z","shell.execute_reply":"2025-11-03T07:35:40.466442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 10: Train - Model 2: Random Forest Regressor**","metadata":{}},{"cell_type":"code","source":"# Initialize the model\nmodel_ran = RandomForestRegressor(random_state=42, n_estimators=200)\n\nmodel_ran.fit(X_train, y_train) # Train the model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:40.468597Z","iopub.execute_input":"2025-11-03T07:35:40.468951Z","iopub.status.idle":"2025-11-03T07:36:05.144178Z","shell.execute_reply.started":"2025-11-03T07:35:40.468923Z","shell.execute_reply":"2025-11-03T07:36:05.143226Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 11: Make Predictions - Model 2: *Random Forest Regressor***","metadata":{}},{"cell_type":"code","source":"y_pred_ran = model_ran.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.145146Z","iopub.execute_input":"2025-11-03T07:36:05.145444Z","iopub.status.idle":"2025-11-03T07:36:05.426216Z","shell.execute_reply.started":"2025-11-03T07:36:05.145417Z","shell.execute_reply":"2025-11-03T07:36:05.425058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_ran","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:35.991958Z","iopub.execute_input":"2025-11-03T07:36:35.992276Z","iopub.status.idle":"2025-11-03T07:36:35.998858Z","shell.execute_reply.started":"2025-11-03T07:36:35.992253Z","shell.execute_reply":"2025-11-03T07:36:35.997827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 12: Evaluate Model - Model 2: *Random Forest Regressor***","metadata":{}},{"cell_type":"code","source":"# Evaluation metrics for Random Forest\nmae_ran = mean_absolute_error(y_test, y_pred_ran)\nmse_ran = mean_squared_error(y_test, y_pred_ran)\nrmse_ran = np.sqrt(mse_ran)\nr2_ran = r2_score(y_test, y_pred_ran)\n\nprint(\"Random Forest Model Performance:\")\nprint(\"Mean Absolute Error:\", round(mae_ran, 2))\nprint(\"Mean Squared Error:\", round(mse_ran, 2))\nprint(\"RMSE:\", round(rmse_ran, 2))\nprint(\"R² Score:\", round(r2_ran, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.427277Z","iopub.execute_input":"2025-11-03T07:36:05.427584Z","iopub.status.idle":"2025-11-03T07:36:05.441699Z","shell.execute_reply.started":"2025-11-03T07:36:05.427558Z","shell.execute_reply":"2025-11-03T07:36:05.440449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 13: Visualize - Model 2: *Random Forest Regressor***","metadata":{}},{"cell_type":"markdown","source":"## -------- 13.1. *Actual vs Predicted Plot*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nsns.scatterplot(x=y_test, y=y_pred_ran)\nplt.xlabel(\"Actual House Value\")\nplt.ylabel(\"Predicted House Value\")\nplt.title(\"Random Forest Regressor: Actual vs Predicted House Prices\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.443194Z","iopub.execute_input":"2025-11-03T07:36:05.443615Z","iopub.status.idle":"2025-11-03T07:36:05.670885Z","shell.execute_reply.started":"2025-11-03T07:36:05.443584Z","shell.execute_reply":"2025-11-03T07:36:05.669897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 13.2. *Error Distribution*","metadata":{}},{"cell_type":"code","source":"errors_ran = y_test - y_pred_ran\nplt.figure(figsize=(7,6))\nsns.histplot(errors_ran, bins=50)\nplt.xlabel(\"Prediction Error\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Random Forest Regressor: Error Distribution\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.671888Z","iopub.execute_input":"2025-11-03T07:36:05.672143Z","iopub.status.idle":"2025-11-03T07:36:05.930546Z","shell.execute_reply.started":"2025-11-03T07:36:05.672123Z","shell.execute_reply":"2025-11-03T07:36:05.929737Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 13.3. *Regression Line Chart*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nplt.plot(y_test.values[:100], label=\"Actual\")\nplt.plot(y_pred_ran[:100], label=\"Predicted\")\nplt.title(\"Random Forest Regressor: Actual vs Predicted (sample 100)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.931308Z","iopub.execute_input":"2025-11-03T07:36:05.931548Z","iopub.status.idle":"2025-11-03T07:36:06.140731Z","shell.execute_reply.started":"2025-11-03T07:36:05.931528Z","shell.execute_reply":"2025-11-03T07:36:06.139686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 14: Compare Model Performances**","metadata":{}},{"cell_type":"code","source":"comp_table = pd.DataFrame({\n    \"Linear Regression\": [mae_lin, mse_lin, rmse_lin, r2_lin],\n    \"Random Forest\": [mae_ran, mse_ran, rmse_ran, r2_ran]\n}, index=[\"MAE\", \"MSE\", \"RMSE\", \"R² Score\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:06.141742Z","iopub.execute_input":"2025-11-03T07:36:06.142123Z","iopub.status.idle":"2025-11-03T07:36:06.147394Z","shell.execute_reply.started":"2025-11-03T07:36:06.142100Z","shell.execute_reply":"2025-11-03T07:36:06.146701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comp_table","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:06.150579Z","iopub.execute_input":"2025-11-03T07:36:06.150969Z","iopub.status.idle":"2025-11-03T07:36:06.166494Z","shell.execute_reply.started":"2025-11-03T07:36:06.150945Z","shell.execute_reply":"2025-11-03T07:36:06.165656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Summary**\n*300-500 words of all the code, including dataset description, preprocessing, model implementation, results, and interpretation*","metadata":{}},{"cell_type":"markdown","source":"In this exercise, I aimed to develop machine learning models to predict the **median house value in California** using the **California Housing Prices dataset**. This dataset comprises **20,640 records** with **9 numerical features**, including median income, housing median age, total rooms, total bedrooms, population, households, latitude, and longitude. The target variable, median_house_value, represents the value of a house in USD, making it suitable for a regression task.\n\nI began by loading the dataset into a pandas DataFrame and inspecting its structure using *.info()*, *.head()*, *.tail()*, *.shape*, and *.describe()*. This initial exploration revealed that all features were numeric and there were no missing values, allowing me to proceed without extensive preprocessing. I then separated the features (*X*) from the target variable (*y*) and split the dataset into training and testing sets using an 80:20 ratio to evaluate model performance on unseen data.\n\nFor model implementation, I first applied **Linear Regression**, a foundational algorithm for predicting continuous variables. I trained the model on the training set and generated predictions on the test set. I evaluated the model using **Mean Absolute Error (MAE)**, **Mean Squared Error (MSE)**, **Root Mean Squared Error (RMSE)**, and **R² Score**, which provided insights into the model's accuracy and generalization. The Linear Regression model achieved an R² score of 0.649, indicating a moderate fit, with MAE and RMSE values highlighting the average prediction error in housing prices.\n\nTo improve performance and capture potential non-linear relationships in the dataset, I implemented a **Random Forest Regressor**, an ensemble learning method that builds multiple decision trees and averages their predictions to reduce overfitting. I trained the Random Forest model on the same training data and generated predictions on the test set. Evaluation metrics showed that the Random Forest model outperformed Linear Regression, with a higher R² score and lower MAE and RMSE, demonstrating its enhanced ability to model complex patterns in the data.\n\nI also visualized the results using scatter plots of actual versus predicted values and residual plots to examine the distribution of prediction errors. These visualizations confirmed that the Random Forest model provided predictions more closely aligned with the true house values, while Linear Regression underperformed for extreme values.\n\nIn conclusion, this exercise allowed me to practice key steps in a regression pipeline, including data inspection, preprocessing, model selection, training, evaluation, and interpretation. Both Linear Regression and Random Forest demonstrated the practical application of supervised learning, with Random Forest offering superior predictive performance. The visualizations and evaluation metrics helped me understand model behavior, quantify prediction accuracy, and interpret the results in a real-world context, reinforcing my understanding of regression modeling and machine learning best practices.","metadata":{}}]}