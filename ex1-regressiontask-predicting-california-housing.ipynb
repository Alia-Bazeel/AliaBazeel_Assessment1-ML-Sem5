{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7876,"sourceType":"datasetVersion","datasetId":5227}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Regression Task: *Predicting California Housing Prices***","metadata":{}},{"cell_type":"markdown","source":"#### Predicting California Housing Prices Using Linear Regression. ***California Housing Prices dataset***","metadata":{}},{"cell_type":"markdown","source":"## **Step 1: Import Libraries**\n#### *The basic libraries that are required for data analysis and machine learning.*","metadata":{}},{"cell_type":"code","source":"import pandas as pd              # for handling data\nimport numpy as np               # for numerical operations\nimport matplotlib.pyplot as plt  # for data visualization\nimport seaborn as sns\nimport sklearn                   # scikit-learn library (machine learning tools)\nfrom sklearn.model_selection import train_test_split # split dataset into training and testing sets\nfrom sklearn.linear_model import LinearRegression    # machine learning algorithm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # evaluating model performance","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:36.753578Z","iopub.execute_input":"2025-11-03T07:35:36.754481Z","iopub.status.idle":"2025-11-03T07:35:39.171230Z","shell.execute_reply.started":"2025-11-03T07:35:36.754438Z","shell.execute_reply":"2025-11-03T07:35:39.170285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 2: Load and Check Data**\n#### *Load the dataset and look at the first few rows to understand the structure.*","metadata":{}},{"cell_type":"code","source":"price = pd.read_csv(\"/kaggle/input/california-housing-prices/housing.csv\")\n\n#print(price)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.172972Z","iopub.execute_input":"2025-11-03T07:35:39.173474Z","iopub.status.idle":"2025-11-03T07:35:39.253347Z","shell.execute_reply.started":"2025-11-03T07:35:39.173441Z","shell.execute_reply":"2025-11-03T07:35:39.252412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.info() #complete information  of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.254358Z","iopub.execute_input":"2025-11-03T07:35:39.254607Z","iopub.status.idle":"2025-11-03T07:35:39.283159Z","shell.execute_reply.started":"2025-11-03T07:35:39.254588Z","shell.execute_reply":"2025-11-03T07:35:39.282212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.head() #first 5 rows of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.285206Z","iopub.execute_input":"2025-11-03T07:35:39.285450Z","iopub.status.idle":"2025-11-03T07:35:39.312089Z","shell.execute_reply.started":"2025-11-03T07:35:39.285430Z","shell.execute_reply":"2025-11-03T07:35:39.311132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.tail() #last 5 rows of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.313000Z","iopub.execute_input":"2025-11-03T07:35:39.313298Z","iopub.status.idle":"2025-11-03T07:35:39.327879Z","shell.execute_reply.started":"2025-11-03T07:35:39.313271Z","shell.execute_reply":"2025-11-03T07:35:39.326956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.shape #number of rows & coloumns of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.328640Z","iopub.execute_input":"2025-11-03T07:35:39.328948Z","iopub.status.idle":"2025-11-03T07:35:39.341794Z","shell.execute_reply.started":"2025-11-03T07:35:39.328917Z","shell.execute_reply":"2025-11-03T07:35:39.340845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price.describe() #statistical summary of numerical columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.342691Z","iopub.execute_input":"2025-11-03T07:35:39.343103Z","iopub.status.idle":"2025-11-03T07:35:39.395487Z","shell.execute_reply.started":"2025-11-03T07:35:39.343079Z","shell.execute_reply":"2025-11-03T07:35:39.394455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 3: Preprocessing Data**\n#### *-Handle missing values*\n#### *-Encode categorical column (ocean_proximity)*\n#### *-Split features/target*","metadata":{}},{"cell_type":"code","source":"price.dropna(inplace=True)    # Drop rows with missing values\n\n# Encode categorical feature using One-Hot Encoding\nprice = pd.get_dummies(price, drop_first=True)\n\n# Define features X and target y\nX = price.drop(\"median_house_value\", axis=1)\ny = price[\"median_house_value\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.396483Z","iopub.execute_input":"2025-11-03T07:35:39.396838Z","iopub.status.idle":"2025-11-03T07:35:39.417552Z","shell.execute_reply.started":"2025-11-03T07:35:39.396807Z","shell.execute_reply":"2025-11-03T07:35:39.416593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.418637Z","iopub.execute_input":"2025-11-03T07:35:39.419041Z","iopub.status.idle":"2025-11-03T07:35:39.424295Z","shell.execute_reply.started":"2025-11-03T07:35:39.419018Z","shell.execute_reply":"2025-11-03T07:35:39.423462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.428362Z","iopub.execute_input":"2025-11-03T07:35:39.428916Z","iopub.status.idle":"2025-11-03T07:35:39.438401Z","shell.execute_reply.started":"2025-11-03T07:35:39.428885Z","shell.execute_reply":"2025-11-03T07:35:39.437355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 4: Split the data into Training and Testing Sets**\n#### *We separate the features (X) and the target (y).*\n#### *Split into 80% training and 20% testing data*","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.439346Z","iopub.execute_input":"2025-11-03T07:35:39.440015Z","iopub.status.idle":"2025-11-03T07:35:39.457726Z","shell.execute_reply.started":"2025-11-03T07:35:39.439986Z","shell.execute_reply":"2025-11-03T07:35:39.456604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.458769Z","iopub.execute_input":"2025-11-03T07:35:39.459062Z","iopub.status.idle":"2025-11-03T07:35:39.464800Z","shell.execute_reply.started":"2025-11-03T07:35:39.459035Z","shell.execute_reply":"2025-11-03T07:35:39.463847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 5: Feature Scaling**","metadata":{}},{"cell_type":"code","source":"# Scaling numerical input data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.465740Z","iopub.execute_input":"2025-11-03T07:35:39.466088Z","iopub.status.idle":"2025-11-03T07:35:39.525437Z","shell.execute_reply.started":"2025-11-03T07:35:39.466063Z","shell.execute_reply":"2025-11-03T07:35:39.524482Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 6: Train - Model 1: Linear Regression**\n#### *We create the model and fit it (train it) on the training data.*","metadata":{}},{"cell_type":"code","source":"model_lin = LinearRegression()         # Initialize Linear Regression Model\nmodel_lin.fit(X_train_scaled, y_train) # Fit model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.526416Z","iopub.execute_input":"2025-11-03T07:35:39.526656Z","iopub.status.idle":"2025-11-03T07:35:39.587233Z","shell.execute_reply.started":"2025-11-03T07:35:39.526637Z","shell.execute_reply":"2025-11-03T07:35:39.586522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 7: Make Predictions - Model 1: Linear Regression**\n#### *Use the trained model to predict on the test set.*","metadata":{}},{"cell_type":"code","source":"y_pred_lin = model_lin.predict(X_test_scaled) # Predict test values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.587861Z","iopub.execute_input":"2025-11-03T07:35:39.588103Z","iopub.status.idle":"2025-11-03T07:35:39.599423Z","shell.execute_reply.started":"2025-11-03T07:35:39.588082Z","shell.execute_reply":"2025-11-03T07:35:39.598724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_pred_lin","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.599971Z","iopub.execute_input":"2025-11-03T07:35:39.600179Z","iopub.status.idle":"2025-11-03T07:35:39.629012Z","shell.execute_reply.started":"2025-11-03T07:35:39.600160Z","shell.execute_reply":"2025-11-03T07:35:39.627156Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 8: Evaluate Model - Model 1: Linear Regression**","metadata":{}},{"cell_type":"code","source":"# Evaluation metrics\nmae_lin = mean_absolute_error(y_test, y_pred_lin)\nmse_lin = mean_squared_error(y_test, y_pred_lin)\nrmse_lin = np.sqrt(mse_lin)\nr2_lin = r2_score(y_test, y_pred_lin)\n\nprint(\"Linear Model Performance:\")\nprint(\"Mean Absolute Error:\", round(mae_lin, 2))\nprint(\"Mean Squared Error:\", round(mse_lin, 2))\nprint(\"RMSE:\", round(rmse_lin, 2))\nprint(\"R² Score:\", round(r2_lin, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.630039Z","iopub.execute_input":"2025-11-03T07:35:39.630330Z","iopub.status.idle":"2025-11-03T07:35:39.649304Z","shell.execute_reply.started":"2025-11-03T07:35:39.630304Z","shell.execute_reply":"2025-11-03T07:35:39.648134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 9: Visualize - Model 1: *Linear Regression***","metadata":{}},{"cell_type":"markdown","source":"## -------- 9.1. *Actual vs Predicted Plot*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nsns.scatterplot(x=y_test, y=y_pred_lin)\nplt.xlabel(\"Actual House Value\")\nplt.ylabel(\"Predicted House Value\")\nplt.title(\"Linear Regression: Actual vs Predicted House Prices\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.651287Z","iopub.execute_input":"2025-11-03T07:35:39.652261Z","iopub.status.idle":"2025-11-03T07:35:39.984390Z","shell.execute_reply.started":"2025-11-03T07:35:39.652231Z","shell.execute_reply":"2025-11-03T07:35:39.983316Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 9.2. *Error Distribution*","metadata":{}},{"cell_type":"code","source":"errors_lin = y_test - y_pred_lin\nplt.figure(figsize=(7,6))\nsns.histplot(errors_lin, bins=50)\nplt.xlabel(\"Prediction Error\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Linear Regression: Error Distribution\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:39.985439Z","iopub.execute_input":"2025-11-03T07:35:39.985781Z","iopub.status.idle":"2025-11-03T07:35:40.257240Z","shell.execute_reply.started":"2025-11-03T07:35:39.985754Z","shell.execute_reply":"2025-11-03T07:35:40.256221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 9.3. *Regression Line Chart*\n#### *Helps show linear relationship*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nplt.plot(y_test.values[:100], label=\"Actual\")\nplt.plot(y_pred_lin[:100], label=\"Predicted\")\nplt.title(\"Linear Regression: Actual vs Predicted (sample 100)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:40.258180Z","iopub.execute_input":"2025-11-03T07:35:40.258478Z","iopub.status.idle":"2025-11-03T07:35:40.467468Z","shell.execute_reply.started":"2025-11-03T07:35:40.258454Z","shell.execute_reply":"2025-11-03T07:35:40.466442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 10: Train - Model 2: Random Forest Regressor**","metadata":{}},{"cell_type":"code","source":"# Initialize the model\nmodel_ran = RandomForestRegressor(random_state=42, n_estimators=200)\n\nmodel_ran.fit(X_train, y_train) # Train the model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:35:40.468597Z","iopub.execute_input":"2025-11-03T07:35:40.468951Z","iopub.status.idle":"2025-11-03T07:36:05.144178Z","shell.execute_reply.started":"2025-11-03T07:35:40.468923Z","shell.execute_reply":"2025-11-03T07:36:05.143226Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 11: Make Predictions - Model 2: *Random Forest Regressor***","metadata":{}},{"cell_type":"code","source":"y_pred_ran = model_ran.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.145146Z","iopub.execute_input":"2025-11-03T07:36:05.145444Z","iopub.status.idle":"2025-11-03T07:36:05.426216Z","shell.execute_reply.started":"2025-11-03T07:36:05.145417Z","shell.execute_reply":"2025-11-03T07:36:05.425058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_ran","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:35.991958Z","iopub.execute_input":"2025-11-03T07:36:35.992276Z","iopub.status.idle":"2025-11-03T07:36:35.998858Z","shell.execute_reply.started":"2025-11-03T07:36:35.992253Z","shell.execute_reply":"2025-11-03T07:36:35.997827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 12: Evaluate Model - Model 2: *Random Forest Regressor***","metadata":{}},{"cell_type":"code","source":"# Evaluation metrics for Random Forest\nmae_ran = mean_absolute_error(y_test, y_pred_ran)\nmse_ran = mean_squared_error(y_test, y_pred_ran)\nrmse_ran = np.sqrt(mse_ran)\nr2_ran = r2_score(y_test, y_pred_ran)\n\nprint(\"Random Forest Model Performance:\")\nprint(\"Mean Absolute Error:\", round(mae_ran, 2))\nprint(\"Mean Squared Error:\", round(mse_ran, 2))\nprint(\"RMSE:\", round(rmse_ran, 2))\nprint(\"R² Score:\", round(r2_ran, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.427277Z","iopub.execute_input":"2025-11-03T07:36:05.427584Z","iopub.status.idle":"2025-11-03T07:36:05.441699Z","shell.execute_reply.started":"2025-11-03T07:36:05.427558Z","shell.execute_reply":"2025-11-03T07:36:05.440449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 13: Visualize - Model 2: *Random Forest Regressor***","metadata":{}},{"cell_type":"markdown","source":"## -------- 13.1. *Actual vs Predicted Plot*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nsns.scatterplot(x=y_test, y=y_pred_ran)\nplt.xlabel(\"Actual House Value\")\nplt.ylabel(\"Predicted House Value\")\nplt.title(\"Random Forest Regressor: Actual vs Predicted House Prices\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.443194Z","iopub.execute_input":"2025-11-03T07:36:05.443615Z","iopub.status.idle":"2025-11-03T07:36:05.670885Z","shell.execute_reply.started":"2025-11-03T07:36:05.443584Z","shell.execute_reply":"2025-11-03T07:36:05.669897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 13.2. *Error Distribution*","metadata":{}},{"cell_type":"code","source":"errors_ran = y_test - y_pred_ran\nplt.figure(figsize=(7,6))\nsns.histplot(errors_ran, bins=50)\nplt.xlabel(\"Prediction Error\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Random Forest Regressor: Error Distribution\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.671888Z","iopub.execute_input":"2025-11-03T07:36:05.672143Z","iopub.status.idle":"2025-11-03T07:36:05.930546Z","shell.execute_reply.started":"2025-11-03T07:36:05.672123Z","shell.execute_reply":"2025-11-03T07:36:05.929737Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## -------- 13.3. *Regression Line Chart*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\nplt.plot(y_test.values[:100], label=\"Actual\")\nplt.plot(y_pred_ran[:100], label=\"Predicted\")\nplt.title(\"Random Forest Regressor: Actual vs Predicted (sample 100)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:05.931308Z","iopub.execute_input":"2025-11-03T07:36:05.931548Z","iopub.status.idle":"2025-11-03T07:36:06.140731Z","shell.execute_reply.started":"2025-11-03T07:36:05.931528Z","shell.execute_reply":"2025-11-03T07:36:06.139686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 14: Compare Model Performances**","metadata":{}},{"cell_type":"code","source":"comp_table = pd.DataFrame({\n    \"Linear Regression\": [mae_lin, mse_lin, rmse_lin, r2_lin],\n    \"Random Forest\": [mae_ran, mse_ran, rmse_ran, r2_ran]\n}, index=[\"MAE\", \"MSE\", \"RMSE\", \"R² Score\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:06.141742Z","iopub.execute_input":"2025-11-03T07:36:06.142123Z","iopub.status.idle":"2025-11-03T07:36:06.147394Z","shell.execute_reply.started":"2025-11-03T07:36:06.142100Z","shell.execute_reply":"2025-11-03T07:36:06.146701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comp_table","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:36:06.150579Z","iopub.execute_input":"2025-11-03T07:36:06.150969Z","iopub.status.idle":"2025-11-03T07:36:06.166494Z","shell.execute_reply.started":"2025-11-03T07:36:06.150945Z","shell.execute_reply":"2025-11-03T07:36:06.165656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Summary**\n*300-500 words of all the code, including dataset description, preprocessing, model implementation, results, and interpretation*","metadata":{}},{"cell_type":"markdown","source":"In this regression task, my goal was to build machine learning models capable of predicting the median value of houses in California using the California Housing Prices dataset. The dataset included 20,640 rows with 9 numerical features, such as median income, housing age, number of rooms and bedrooms, population, households, and the geographical coordinates. Since the target variable was the median house value in USD, the task naturally fit the structure of a regression problem.\n\nI started by loading the dataset into a pandas DataFrame and exploring its basic structure using functions like .info(), .describe(), .head(), .tail(), and .shape. This initial step helped me confirm that the dataset had no missing values and that all the features were numerical. Because of this, I did not need any major preprocessing, which allowed me to move quickly into separating the features (X) and the target (y). I then used an 80:20 split for training and testing to ensure that the models were fairly evaluated.\n\nThe first model I implemented was Linear Regression, which is a simple and widely used approach for predicting continuous values. After training the model on the training set, I generated predictions for the test set and evaluated the results using MAE, MSE, RMSE, and R². The Linear Regression model achieved an R² score of 0.649, showing a moderate level of predictive power. The error metrics also indicated how far off the predictions were from the actual house values.\n\nTo improve performance, I then used a Random Forest Regressor. This model creates multiple decision trees and combines their outputs, making it more effective at capturing complex and non-linear relationships in the data. After training it on the same dataset, I observed clear improvements in the evaluation metrics. The Random Forest model achieved a higher R² score and produced lower error values across MAE, MSE, and RMSE, showing that it was able to model the patterns in the data more accurately than Linear Regression.\n\nI also created visualizations, including scatter plots of predicted versus actual values and residual plots. These helped me see how well each model performed. The Random Forest plots showed predictions that stayed closer to the real values, while the Linear Regression model struggled more with extreme cases.\n\nOverall, this exercise helped me understand the complete workflow of a regression project—from exploring and preparing the data to selecting models, training them, and interpreting their results. Comparing both models showed me the strengths and limitations of each approach and deepened my understanding of how machine learning models behave in practical situations.","metadata":{}}]}